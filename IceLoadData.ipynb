{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreasSjolander/IceLoadsOnDams/blob/main/IceLoadData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ice Load Data Rätan\n",
        "\n",
        "In this notebook, data from ice panels at Rätan will be analyzed. The data is read from Google Drive. The spreadsheet should be manually filtered first so that the first row contains the name of the columns and the second row contains the unit of the data.\n",
        "\n",
        "1. Import of Modules\n",
        "2. Setup Work Directory\n",
        "3. Import and Cleaning of Data\n",
        "3. Visualization of Dataset\n"
      ],
      "metadata": {
        "id": "zIt5hs5YK2Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import seaborn as sns\n",
        "# To visualize dataframes import display\n",
        "from IPython.display import display\n",
        "# Enable plotting inside the notebook\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "pInENY03K-10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Work Directory\n",
        "Here, a link to Google Drive and Github is established together with the work directory to the data and to store plots. A list of all data is then created."
      ],
      "metadata": {
        "id": "lXZ-MuXM-VRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### LINK GOOGLE DRIVE AND GITHUB\n",
        "# Import Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a data path\n",
        "# /content/drive/MyDrive/ is the default path to the root of the Google Drive\n",
        "pa_da1 = '/content/drive/MyDrive/KTH/IceProject/Data_Ratan'\n",
        "pa_da2 = '/content/drive/MyDrive/KTH/IceProject/Data_2'\n",
        "pd_fig = '/content/drive/MyDrive/KTH/IceProject/Plots'\n",
        "\n",
        "# Link Github Repository\n",
        "# Code here...\n",
        "\n",
        "# Set the work directory\n",
        "os.chdir(pa_da1)\n",
        "print (os.listdir())\n",
        "\n",
        "#### READ IN FILES WITH NEW NAME\n",
        "# Find all files of specified type defined by: filetype\n",
        "filetype = '*.xlsx'\n",
        "Xlist = filetype\n",
        "# Create an empty vector to store filenames in\n",
        "filex = []\n",
        "# Store all filenames defined above\n",
        "for fx in glob.glob(Xlist, recursive=True):\n",
        "    filex.append(fx)\n",
        "print(\"A list of all files \\n\")\n",
        "print(filex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "7kQcToDLVZId",
        "outputId": "6e8e3036-baa6-448c-85a5-e77764c2af9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3f3748e07360>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Import Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create a data path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Importing and Cleaning of Data\n",
        "\n",
        "Data is avaible in Excel format with a timestamp in the format:\n",
        "\n",
        "1. Read in the data from Excel - OK\n",
        "2. Clean the data\n",
        "2a. Find row with HMB - OK\n",
        "Drop other rows that contain text - OK\n",
        "Set row with HMB to index - OK2\n",
        "Drop columns that don't contain load or time - OK\n",
        "Translate time-signal to time-date\n",
        "Done!"
      ],
      "metadata": {
        "id": "bc2PSiGmLFmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# READ THE DATA TO PANDAS AND PLOT\n",
        "###\n",
        "\n",
        "\"\"\" create loop to read in data.\n",
        "df_temp = A temporary Panda frame with data from simulations.\n",
        "li_0 = list with all filenames without extension\n",
        "df_dict = a dictionary where the filename is the key and the datapoints stored\n",
        "as data\n",
        "col = a list with names of the columns that should be used\n",
        "\n",
        "pd.filter is used to filter out the interesting columns, i.e. the first column\n",
        "which contain the timestamp and the HBM columns which is the data from the load\n",
        "cell.\n",
        "Column names are dropped since the names could be inconsistent from different\n",
        "files.\n",
        "\"\"\"\n",
        "\n",
        "# Create empty dictionary to store data in\n",
        "df_dict = {}\n",
        "# Create empty list to store filenames in\n",
        "li_0 = []\n",
        "# Create a list to label columns\n",
        "col = [\"Time\", \"HMB_1\", \"HMB_2\", \"HMB_3\"]\n",
        "# header= None,\n",
        "\n",
        "# Define a loop\n",
        "for f in filex :\n",
        "    #data = data.dropna()\n",
        "    df_temp = pd.read_excel(f, skiprows=(0))\n",
        "    # Drop columns that don't contain important data\n",
        "    df_temp = df_temp.filter(regex='HBM|Time')\n",
        "    # Drop first row (contains units)\n",
        "    df_temp = df_temp.drop(labels=0, axis=0)\n",
        "    # Rename column names\n",
        "    df_temp.columns = col\n",
        "    # Create time column and convert to correct format\n",
        "    #df_temp[\"Time_2\"] = pd.to_datetime(df_temp[\"Time\"],format='%H:%M:%S.%f', errors='coerce')\n",
        "    # Create a column for average load\n",
        "    df_temp[\"Load_Avg\"] = (df_temp.HMB_1+df_temp.HMB_2+df_temp.HMB_3)/3\n",
        "    # Create a column to calculate the resultatn load\n",
        "    # Code here\n",
        "    # Create a column to calculate the position of the resultant\n",
        "    # Code here\n",
        "    # DROP FILE EXTENSION\n",
        "    base, ext = os.path.splitext(f)\n",
        "    li_0.append(base)\n",
        "    # BUILD DICTIONARY\n",
        "    df_dict[base] = df_temp\n",
        "\n",
        "print(df_temp)\n",
        "\n"
      ],
      "metadata": {
        "id": "wymfbdDuLJnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Plotting the data\n",
        "Below, the data is plotted."
      ],
      "metadata": {
        "id": "I8_H5UZr-6lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the strength of the concrete for different cement and binder content and wc ratios and age\n",
        "plt.figure(1)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15,10))\n",
        "sns.lineplot(data=df_temp, x='Time', y='HMB_1', ax=axes[0,0])\n",
        "axes[0,0].set_title('Load Cell #1')\n",
        "sns.lineplot(data=df_temp, x='Time', y='HMB_2', ax=axes[0,1])\n",
        "axes[0,1].set_title('Load Cell #2')\n",
        "sns.lineplot(data=df_temp, x='Time', y='HMB_3', ax=axes[1,0])\n",
        "axes[1,0].set_title('Load Cell #3')\n",
        "sns.lineplot(data=df_temp, x='Time', y='Load_Avg', ax=axes[1,1])\n",
        "axes[1,1].set_title('Load Average')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QutlX2xg_AOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}